For the duration of its existence, each process is represented
by a `process control block' (PCB) which contains information such as:

   - state of the process (ready, running, blocked)
   - register values
   - priorities and scheduling information
   - memory management information
   - accounting information
   - allocated resources

Specifics of a PCB depend on the system and techniques used.

Process Scheduling:

Allocating the CPU to a different process to reduce idle time.

Each process change requires a `context switch'.

A context switch is _pure overhead_, i.e., involves no useful work

Scheduling Management:

Processes are managed through the use of multiple queues (or lists)
of PCB's; the word `queue' (in an OS context) has a loose interpretation.

The job queue contains all jobs submitted to the system, but not
yet in main memory.

The ready queue contains all jobs ready to execute.

Each I/O device has a queue of jobs waiting for various I/O operations.

A process is dispatched from the ready queue to the CPU; its processing
may cause it to be put on a device queue.

All of these events are signaled by interrupts.

Process Creation:

An initial OS process begins running at boot time, which spawns (creates)
other processes.

A process hierarchy (tree) evolves with parent-child relationships.

Cooperating Processes:

Various processes share data.

Cooperating processes must communicate and synchronize activities.

One classic example: consumer/producer example.

There are relationships between processes:

CPU and I/O Bursts:

A process cycles between CPU processing and I/O activity.

CPU Bursts:

A process generally has many short CPU bursts or a few long CPU bursts.

I/O bound processes have many short CPU bursts.
CPU bound processes have few long CPU bursts.

This can effect the choice of CPU scheduling algorithm used in an OS.

Process Life Cycle:

5 state diagram

A process moves through various states during its life.

Many processes may be ready or waiting at the same time, but only one can be
running at a time in a uniprocessor system.

Process (or CPU) Scheduling:

Preemptive Scheduling:

CPU scheduling decisions may take place when a process

1) switches from the running to waiting state

2) switches from the running to ready state

3) switches from the waiting to ready state

4) terminates

Scheduling under conditions 1 and 4 is called `non-preemptive' (context
switch is caused by the running program).

Scheduling under conditions 2 and 3 is `preemptive' (context switch
caused by external reasons).

Scheduling Criteria:

Each scheduling algorithm favors particular kinds of scheduling.

Some criteria to consider:

   - CPU utilization (maximize)
 
   - Throughput: # of processes which complete execution per time unit
     (maximize)

   - Turnaround time: total amount of time to execute a particular process
     (minimize)

   - Waiting time: amount of time a process has been waiting in the
     ready queue (minimize)

   - Response time: amount of time it takes from when a request is submitted
     to when the response is produced (minimize); does not include
     the time for a response to be output.

     Some work is being done to minimize the response time variance, to
     promote predictability.

CPU Scheduling Algorithms
   - First-Come, First Serve (FCFS or FIFO)
   - Shortest Job First (SJF)
   - Priority
   - Round Robin
   - Multi-level Queue
   - Multi-level Feedback Queue

First-Come, First Serve
   - Non-preemptive scheduling management
   - Ready queue is managed as a FIFO queue

   - example: 3 jobs arrive at time 0 in the following order (batch
     processing):

Process    Burst Time  Arrival   Start    Wait   Finish  TA
-----------------------------------------------------------
 1         24                0       0       0       24  24
 2          3                0      24       24      27  27
 3          3                0      27       27      30  30

Gantt chart:

P1                P2     P3
0 ............... 24 . . 27 . . 30

Average Waiting Time: (0+24+27)/3 = 17

Average Turnaround Time: (24+27+30) = 27

Consider arrival order: 2, 3, 1

Process    Burst Time  Arrival   Start    Wait   Finish  TA
-----------------------------------------------------------
 2          3                0       0       0        3   3 
 3          3                0       3       3        6   6
 1         24                0       6       6       30  30 

Gantt chart:

P2   P3   P1
0 .. 3 .. 6 ............. 30

Average Waiting Time: (0+3+6)/3 = 3

Average Turnaround Time: (3+6+30) = 13

--

Process    Burst Time  Arrival   Start    Wait   Finish  TA
-----------------------------------------------------------
1          12               0      0       0      12     12
2          6                1     12      11      18     17
3          9                4     18      14      27     23

















Gantt chart:

P1     P2           P3
0 .... 12 . . . . . 18 ... 27

Average Waiting Time: (0+11+14)/3 = 8.33

Average Turnaround Time: (12+17+23) = 52/3 = 17.33



Shortest Job First (SJF):

Associate with each process the length of its next CPU burst.

Schedule the process with the shortest time.

Two schemes:

non-preemptive: once scheduled, a process continues until the end of its
CPU burst.

preemptive: preempt if a new process arrives with a CPU burst of less length
             than the _remaining time_ of the currently executing process.

The preemptive scheme is known as the `Shortest Remaining Time First' (SRTF)
algorithm.

SJF is provably optimal; it yields a minimum average waiting time for
any set of processes.

However, we cannot always predict the future, i.e., we do not know the
next burst length.

SJF (non-preemptive):

Process    Burst Time  Arrival   Start    Wait   Finish  TA
-----------------------------------------------------------
1           7               0      0       0       7      7
2           4               2      8       6       12    10
3           1               4      7       3       8      4
4           4               5     12       7       16    11



Gantt chart:

P1            P3  P2      P4
0 . . . . . . 7 . 8 . . . 12 . . . 16














Average Waiting Time: (0+6+3+7)/4 = 4

Average Turnaround Time: (7+4+10+11)/4 = 8

SRTF (preemptive):

Process    Burst Time  Arrival   Start    Wait   Finish  TA
-----------------------------------------------------------
1           7               0      0       9       7      7
2           4               2      

(now too hard to do this way)















Gantt chart:

P1  P2  P3 P2  P4      P1
0 1 2 3 4  5 . 7 . . . 11 . . . . 16

Average Waiting Time: (9+1+0+2)/4 = 3















Average Turnaround Time: (16+5+1+6)/4 = 7





How can we know the length of the next CPU burst?

We can only estimate its length.






An estimate can be formed by using the length of its previous CPU bursts:

1) T_n = actual length of the nth CPU burst
2) psi_n = predicted value of nth CPU burst
3) 0 <= w <= 1
4) define psi_(n+1) = w * T_n + (1-w) * psi_n




















Priority Scheduling:

Associate a priority with each process, allocate the CPU to the process
with the highest priority.

Any 2 processes with the same priority are handled FCFS.

SJF is a version of priority scheduling where the priority is defined
using the predicted CPU burst length.

Priorities are usually numeric over a range.

High #'s may indicate low priority (system dependent).

Internal (process-based) priorities: time limits, memory requirements,
resources needed, burst ratio.

External (often political) priorities: importance, source (e.g., faculty,
student).

Priority scheduling can be non-preemptive or preemptive.

Problem: `starvation: low priority processes may never execute
(because they are waiting indefinitely for the CPU).

A solution: `aging': increase the priority of a process as time
progresses.

Round Robin:

Time sharing (preemptive) scheduler where each process is given access
to the CPU for 1 time quantum (slice), e.g, 20 milliseconds

A process may block itself before its time slice expires.

If it uses its entire time slice, it is then preempted and put at the
end of the ready queue.

The ready queue is managed as a FIFO queue and treated as a circular.

If there are n processes on the ready queue and the time quantum is q,
then each process gets 1/n time on the CPU in chunks of at most q time
units.













No process waits for more than (n-1)q time units.

The choice of how big to make the time slice (q) is extremely important.
   - If q is very large, Round Robin degenerates into FCFS.

   - If q is very small, the context switch overhead defeats the benefits.

Process    Burst Time  Arrival   Start    Wait   Finish  TA
-----------------------------------------------------------
1           53               0      0       ?       154    154
2           17               0     20       ?       37     37
3           68               0     37       ?       182    182
4           24               0     57       ?       121    121

Gantt chart:

P1     P2    P3      P4      P1       P3      P4      P1       P3     P3
0......20....37......57......77.......97......117.....121......134....154....162

Waiting times:

P1: (77-20) + (121-97) = 81

P2: (20-0) = 20

P3: (37-0) + (97-57) + (134-117) = 94

P4: (57-0) + (117-77) = 97

Average Waiting Time: (81+20+94+97)/4 = 73

--
Multilevel Queue:

The ready queue is managed as multiple queues based on various
characteristics, e.g.,

   - foreground (interactive)
   - background (batch)

Each queue uses a particular scheduling algorithm, e.g.,

   - foreground (round robin)
   - background (FCFS)

Scheduling must be done between queues,
   - fixed priority (may lead to starvation), e.g., foreground jobs
       have absolute priority over background jobs 
   - time slice per queue

Multilevel Feedback Queue:

Processes move between the various queues.  Multilevel feedback
queue is characterized by

   - # of queues
   - scheduling algorithm for each queue
   - method used to determine when to upgrade a process
   - method used to determine when to demote a process
   - method used to determine on which queue a process begins 
     (each time it returns to the ready state)

For example:
   - 3 queues
   - fixed priority based on length of CPU burst
   - RR for 1st queue, FCFS for last queue
   - each process begins on top queue (quantum = 8)

--> [ q = 8] -->
--> [ q = 16] -->
--> [ FCFS ] -->

Algorithm Evaluation:

Which algorithm should be used in a particular system?

How should the parameters, e.g., q, #levels, be defined?

On which criteria do we base our decisions?

Four approaches to evaluation:

   - deterministic modeling
   - queue models
   - simulation
   - implementation

Deterministic Modeling:

Define a workload and compare it across algorithms.

Simple to execute and results in distinct values to compare.

However, the results apply only to that case and cannot be generalized.

A set of workload scenarios with varying characteristics can be
defined and analyzed.

Must be careful about any conclusion drawn.

Queuing Models:

n = average queue length

W = average waiting time in the queue

lambda = average arrival rate

Little's Formula: n = lambda * W

Little's formula can be applied to the CPU and ready queue, or the wait
queue for any device.

Values can be obtained by measuring a real system over time and mathematically
estimating.

The estimates are not always accurate due to:
   - complicated algorithms
   - assumptions

Therefore, the queuing model may not reflect reality to the level needed.
